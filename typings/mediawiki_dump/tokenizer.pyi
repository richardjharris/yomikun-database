"""
This type stub file was generated by pyright.
"""

from typing import Callable, List

"""
Cleans and tokenizes given text
"""

def clean(text: str) -> str:
    """Cleans up the provided wikitext.
    Removes templates, tables, parser hooks, magic words, HTML tags and file embeds.
    Keeps links.
    """
    ...

def tokenize_filter(text: str) -> bool:
    """Used by tokenize function below. Ignores numbers when tokenizing cleaned up wikitext."""
    ...

def tokenize(text: str, filter_func: Callable[[str], str] = ...) -> List[str]:
    """Tokenizes a given text. Usually you want to first pass it via clean() function."""
    ...
